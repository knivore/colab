{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhuHJAxY/VOel2uXxcI3uT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/knivore/colab/blob/main/Internal_Knowledge_Base_Q%26A_Using_LangChain_%26_OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Internal Knowledge Base Q&A Bot Using LangChain & OpenAI\n",
        "\n",
        "This example shows how to query an internal knowledge base stored\n",
        "\n",
        "This notebook is adapted from LangChain's [Question Answering](https://python.langchain.com/docs/use_cases/question_answering/) use case."
      ],
      "metadata": {
        "id": "X0FWmVGy5NcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installations\n"
      ],
      "metadata": {
        "id": "K57awAmb6LL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install faiss-cpu\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw0Y9wxs5W9A",
        "outputId": "5d2643ae-e795-4e40-c43a-20e5d15c1628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.263)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.19)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.14)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.22)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.7.4)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup OPENAI_API_KEY and other variables"
      ],
      "metadata": {
        "id": "qGEDaC27_vto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "\n",
        "DOCUMENT_BASE_URL = \"https://www.govbenefits.gov.sg/am-i-eligible/ap-cash\"  # Actual URL\n",
        "FAISS_DATA_STORE_DIR = \"faiss_data_store\"  # Folder to save/load the database"
      ],
      "metadata": {
        "id": "wNQXmIHeAA2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the datastore\n",
        "\n",
        "* Side note: [LangChain Integrations](https://integrations.langchain.com/) has a list of 154 types of document loaders\n",
        "\n"
      ],
      "metadata": {
        "id": "b0NgmOBICsje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = WebBaseLoader(f\"{DOCUMENT_BASE_URL}\")\n",
        "data = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 0)\n",
        "split_data = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "nGCQ9_NsC-4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the vector data\n",
        "\n",
        "* Side note: [LangChain Integrations](https://integrations.langchain.com/) has a list of 37 types of embeddings models & 46 types of vector stores"
      ],
      "metadata": {
        "id": "ka9CcsEcEUFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vector_store = FAISS.from_documents(split_data, embeddings)"
      ],
      "metadata": {
        "id": "Vjf02BEoETTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPTIONAL: Save to local"
      ],
      "metadata": {
        "id": "9-QKF0owF9Rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to a local FAISS index. So don't have to recreate it every time you use it.\n",
        "if os.path.exists(path=FAISS_DATA_STORE_DIR):\n",
        "    local_index = FAISS.load_local(folder_path=FAISS_DATA_STORE_DIR, embeddings=embeddings)\n",
        "    local_index.merge_from(target=vector_store)\n",
        "    local_index.save_local(folder_path=FAISS_DATA_STORE_DIR)\n",
        "else:\n",
        "    vector_store.save_local(folder_path=FAISS_DATA_STORE_DIR)"
      ],
      "metadata": {
        "id": "ZhETUclUGAhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPTIONAL: Load from local"
      ],
      "metadata": {
        "id": "aenfQbtRI5ht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = FAISS.load_local(folder_path=FAISS_DATA_STORE_DIR, embeddings=embeddings)"
      ],
      "metadata": {
        "id": "XvYWocd9I8oU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query ChatGPT with vector store\n",
        "\n",
        "Setting up chat model and prompts"
      ],
      "metadata": {
        "id": "ozzAGwY5JQXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "system_template = \"\"\"\n",
        "If you need any details clarified, please ask questions until all issues are clarified.\n",
        "For tabular information return it as an html table. Do not return markdown format.\n",
        "Take note of the sources and include them in the answer and provide URL links to the source itself.\n",
        "If you do not know the answer, just say that \"I don't know\", do not ever try to make up an answer.\n",
        "----------------\n",
        "{summaries}\"\"\"\n",
        "messages = [\n",
        "    SystemMessagePromptTemplate.from_template(system_template),\n",
        "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "]\n",
        "prompt = ChatPromptTemplate.from_messages(messages)\n",
        "\n",
        "#llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.0)\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.0)  # Set the temperature to 0.0 as we don't want creative answer\n",
        "\n",
        "# Stuff - The full text of all retrieved documents is stuffed into the LLM prompt. This provides maximum context at the expense of potential repetition. Could increase the tokens sent to the model\n",
        "stuff_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vector_store.as_retriever(),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": prompt}\n",
        ")\n",
        "\n",
        "# Refine - The retrieved documents are summarized into a short context paragraph which is then provided to the LLM. This helps reduce repetition.\n",
        "refine_chain_retriever = vector_store.as_retriever()\n",
        "refine_chain_retriever.search_kwargs['distance_metric'] = 'cos'  # Read more on https://weaviate.io/blog/distance-metrics-in-vector-search\n",
        "refine_chain_retriever.search_kwargs['fetch_k'] = 25  # Set how many documents you want to fetch before filtering\n",
        "refine_chain_retriever.search_kwargs['maximal_marginal_relevance'] = True\n",
        "refine_chain_retriever.search_kwargs['k'] = 10  # Top documents matches\n",
        "\n",
        "refine_chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"refine\",\n",
        "    retriever=refine_chain_retriever,\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "\n",
        "def print_result(results):\n",
        "    output_text = f\"\"\"\n",
        "    * 🤖 Reply: {results['answer']}\n",
        "    * 📚 All relevant sources:\n",
        "    {' '.join(list(set([doc.metadata['source'] for doc in results['source_documents']])))}\n",
        "    \"\"\"\n",
        "    print(output_text)"
      ],
      "metadata": {
        "id": "10sXvs4NJq7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ask away!"
      ],
      "metadata": {
        "id": "z19ScWDiK_gR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Assurance Package?\"\n",
        "result = stuff_chain(query)\n",
        "# result = refine_chain({\"question\": query})\n",
        "print_result(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9R00IKpZES4",
        "outputId": "a8990cc7-a83a-4635-b57b-e906ce5b3b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    * 🤖 Reply: The Assurance Package is a government initiative in Singapore that provides various forms of assistance and support to Singaporeans. It includes cash payments, MediSave top-ups, U-Save rebates, Seniors' Bonus, Cost of Living Special Payment, and CDC Vouchers. The package aims to help Singaporeans cope with the cost of living and provide additional support to those who need it. The specific benefits and eligibility criteria vary for each component of the Assurance Package.\n",
            "    * 📚 All relevant sources: \n",
            "    https://www.govbenefits.gov.sg/am-i-eligible/ap-cash\n",
            "    \n"
          ]
        }
      ]
    }
  ]
}